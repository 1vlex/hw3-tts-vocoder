# Отчет по HW3 TTS Vocoder

## 1. Выбранная модель

- **Статья:** HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis (2020)
- **Почему выбрал:** из предложенных вариантов HiFi-GAN является наиболее удобным для базовой реализации вокодера с нуля. Архитектура хорошо подходит для учебного задания: понятная схема генератора (mel -> waveform), стандартный набор discriminator'ов и широко используемые loss-функции.

---

## 2. Архитектура

### Generator
Реализован HiFi-GAN-подобный генератор:
- вход: log-mel спектрограмма (`[B, 80, T]`)
- последовательность upsampling-блоков (transposed conv)
- сверточные residual-блоки между этапами апсемплинга
- выход: waveform (`[B, 1, T_audio]`)

Использовалась упрощенная baseline-конфигурация (без дополнительных архитектурных улучшений).

### Discriminators
Использован набор дискриминаторов в духе HiFi-GAN:
- **Multi-Period Discriminator (MPD)** - несколько discriminator'ов по разным периодам
- **Multi-Scale Discriminator (MSD)** - несколько discriminator'ов на разных временных масштабах

Это позволяет лучше контролировать как локальную структуру сигнала, так и периодичность речевого/гармонического содержимого.

### Лоссы
Использовалась стандартная комбинация:
- **Adversarial loss** (для генератора и дискриминаторов)
- **Feature Matching loss**
- **Mel reconstruction loss** (L1 по mel-признакам между оригиналом и синтезом)

Именно mel-loss дает быстрый прогресс в начале обучения, а adversarial + feature matching улучшают perceptual quality.

### Mel-конфиг
Использовалась mel-конфигурация (совместимая в train/infer):
- `sample_rate = 22050`
- `n_fft = 1024`
- `win_length = 1024`
- `hop_length = 256`
- `n_mels = 80`
- `f_min = 0`
- `f_max = 11025`
- log-mel через `clamp + log`

---

## 3. Данные

### Датасет
Использован датасет **RUSLAN** (русская речь) для обучения вокодера.

### Сплиты
В baseline-версии использовался упрощенный режим:
- train/val на основе одной директории с `.wav` (без отдельного фиксированного сплита по метаданным)

Это допустимо для базовой проверки реализации и получения рабочего вокодера, но для более строгой оценки желательно формировать отдельный train/val split.

### Препроцессинг
- загрузка `.wav`
- приведение к mono
- (при необходимости) ресемплинг
- извлечение log-mel спектрограмм
- случайная нарезка сегментов waveform фиксированной длины для обучения

### Ресемплинг
Выбран режим **22050 Hz**:
- снижает вычислительную нагрузку
- стандартный и удобный вариант для TTS/vocoder baseline
- позволяет быстрее обучать и проверять инференс

---

## 4. Эксперименты

### Baseline
Реализована и обучена упрощенная baseline-версия HiFi-GAN-подобного вокодера:
- обучение с нуля (без предобученных вокодеров)
- adversarial + feature matching + mel loss
- инференс через `synthesize.py`
- поддержка режима **resynthesis** (ground-truth audio -> mel -> vocoder -> audio)

Результат baseline:
- речь разборчива
- интонация в целом сохраняется
- присутствует заметный роботизированный оттенок голоса

### Улучшение 1
В финальную версию дополнительные архитектурные улучшения не добавлялись.
Фокус был на:
- рабочей реализации baseline
- воспроизводимости
- корректном инференсе
- Colab demo
- логировании эксперимента в CometML

### Улучшение 2
Не проводилось.

---

## 5. Логи обучения

- Логирование: **CometML**
- Ссылка на эксперимент:
  - https://www.comet.com/1vlex/hw3-tts-vocoder/9530bf5d8ca04618abf110639234bbff?compareXAxis=step&experiment-tab=panels&showOutliers=true&smoothing=0&viewId=new&xAxis

### Наблюдения по логам
- `train/loss_mel` быстро снижается в начале обучения, затем выходит на плато
- `val/mel_l1` улучшается на раннем этапе, после чего прогресс замедляется
- adversarial/discriminator loss стабилизируются, но субъективное качество перестает заметно расти после нескольких эпох

### Время и ресурсы
- Локальная машина: **Windows**, GPU **RTX 5070 Ti (16 GB)**
- По наблюдениям:
  - ~4-5 ГБ VRAM при выбранных настройках
  - порядка ~6 минут на эпоху (в baseline-конфигурации)

---

## 6. Анализ качества (Слуховые наблюдения)

### 6.1 На обучающих данных (resynthesis, 15 файлов)

Проведен анализ **15 файлов** из RUSLAN в режиме **resynthesis**:
- исходное аудио -> mel -> вокодер -> синтезированное аудио

#### Слуховые наблюдения
- текст в большинстве случаев хорошо различим
- слова понятны и распознаются без существенных проблем
- базовая интонация и ритм фразы в целом сохраняются
- основной артефакт - **роботизированный/металлический оттенок** тембра
- артефакты присутствуют, но не являются главным ограничением разборчивости (по сравнению с тембром)

---

### 6.2 На внешних данных (MOS 1.wav, 2.wav, 3.wav)

Для оценки вокодера использовались ground-truth аудио из набора MOS (как требуется в задании), в режиме **resynthesis**.

#### Наблюдения
- речь остается понятной
- длинные фразы воспроизводятся без полного развала структуры
- интонационный контур сохраняется
- роботизированный оттенок сохраняется и заметен на слух

#### Сравнение с обучающими данными
Выводы в целом совпадают с анализом на RUSLAN:
- разборчивость приемлемая
- натуральность тембра ограничена
- на внешних данных артефакты субъективно могут восприниматься сильнее

#### Вывод по внешним данным
Модель пригодна для демонстрации базового vocoder pipeline и resynthesis, но для высокого MOS требуется усиление архитектуры и/или более качественная настройка обучения.

---

### 6.3 Анализ временной и частотно-временной областей

Для качественного анализа использовалось сравнение:
- waveform (оригинал vs синтез)
- log-mel представлений (оригинал vs синтез)

#### Наблюдения по waveform
- временная структура сигнала в целом сохраняется: участки речи и паузы совпадают по расположению
- макродинамика амплитуды похожа на оригинал
- у сгенерированного сигнала заметна большая шероховатость/искусственность формы, что согласуется со слуховым ощущением роботизированности

#### Наблюдения по log-mel
- общая спектральная структура речи сохраняется
- формантная/энергетическая картина близка к оригиналу на уровне общей структуры
- различия проявляются в деталях и "гладкости" спектральной картины, что отражается на тембре и натуральности

---

### 6.4 Анализ всей TTS системы (Full TTS, proxy-эксперимент)

Для выполнения пункта про анализ полной TTS системы был добавлен отдельный эксперимент `full_tts.py`.

#### Что именно было сделано
В Windows-среде использован практический proxy-вариант полного пайплайна:
- внешний русскоязычный TTS (MMS, Hugging Face) генерирует аудио по тексту
- далее из этого аудио извлекается mel-спектрограмма тем же кодом проекта
- полученный mel подается в мой вокодер HiFi-GAN

Итого анализируем цепочку:
- `text -> external TTS waveform -> mel -> my vocoder -> waveform`

Это не "чистая" схема acoustic model (text-to-mel) + vocoder, но позволяет проверить поведение моего вокодера на **синтетических признаках**, что по смыслу соответствует задаче анализа полной системы.

#### Какие тексты использовались
- **Часть 1 (RUSLAN test-like):** 3 текста из `metadata_RUSLAN_22200.csv`
- **Часть 2 (внешние MOS тексты):** 3 предложения из раздела MOS
- дополнительно 3 коротких пользовательских фразы для быстрой проверки

#### Слуховые наблюдения (сравнение с resynthesis)
По сравнению с режимом resynthesis (ground-truth audio -> mel -> vocoder), в Full TTS proxy-режиме:
- итоговый звук **немного хуже**
- **текст остается различимым**
- появляется **чуть больше шума**
- голос становится **более роботизированным**
- заметно **слабее передается интонация**
- местами ухудшается естественность ударений и фразового акцента

#### Ответы на вопросы из задания (анализ всей TTS системы)

**Какие новые артефакты появились по сравнению с resynthesis режимом?**
- усилился шумовой фон/шероховатость
- сильнее проявилась роботизированность тембра
- ухудшилась интонационная выразительность
- местами слышна неестественная просодия (ударения, паузы, акценты)

**Можно ли различить влияние акустической модели и вокодера на качество?**
Да, частично.
- если сравнивать `external TTS wav` и `wav после моего вокодера`, то видно, что часть проблем уже присутствует на стороне внешней TTS (просодия, ударения, интонация)
- после повторной вокодеризации мой вокодер добавляет/усиливает артефакты тембра и шум, а также немного "сглаживает" детали
- таким образом, просодические ошибки в большей степени связаны с upstream TTS, а роботизированность и часть шумов усиливаются на этапе вокодера

**Какие ограничения TTS системы обнаружены?**
- итоговое качество сильно зависит от качества upstream-признаков/внешнего TTS
- при переходе от "идеальных" mel (из ground-truth аудио) к синтетическим признакам качество заметно падает
- разборчивость сохраняется лучше, чем натуральность и интонация
- для русского языка важна корректная просодия (ударения, интонация), и ошибки на этом уровне резко ухудшают субъективное качество даже при понятном тексте

#### Вывод по Full TTS
Full TTS proxy-эксперимент показал, что мой вокодер остается рабочим и сохраняет разборчивость текста, но при синтетических признаках:
- качество ниже, чем в resynthesis
- шум и роботизированность усиливаются
- интонация и ударения передаются хуже

Это подтверждает, что качество полной TTS системы определяется совместно:
- качеством акустической/внешней TTS части
- качеством вокодера
- согласованностью между ними

---

## 7. Что сработало / что не сработало

### Что сработало
- Реализация baseline vocoder (HiFi-GAN-подобный) обучается с нуля и работает в режиме resynthesis
- `synthesize.py` корректно сохраняет выходные аудиофайлы
- Реализован `CustomDirDataset` под формат `audio/ + transcriptions/`
- Подготовлен и проверен **Google Colab demo**
- Настроено логирование в **CometML**
- Добавлен скрипт скачивания чекпоинта (`download_checkpoints.py`), включая вариант загрузки с Google Drive
- Добавлен Full TTS proxy-эксперимент (`full_tts.py`) и проведен слуховой анализ результатов

### Что не сработало / ограничения
- Натуральность звука осталась на baseline-уровне (заметный роботизированный оттенок)
- После нескольких эпох субъективное качество перестало заметно улучшаться
- Не проводились архитектурные улучшения / абляции
- В текущем Full TTS анализе использован proxy-вариант (external TTS waveform -> mel -> vocoder), а не отдельная text-to-mel акустическая модель

---

## 8. Основные сложности

- Сборка воспроизводимого пайплайна: локальное обучение + Colab инференс
- Корректная загрузка чекпоинта через скрипт (в т.ч. Google Drive)
- Структура проекта и импорты для запуска в Colab
- Подбор конфигурации, которая стабильно обучается и укладывается в доступные ресурсы
- Достижение perceptual quality: разборчивость достигается быстрее, чем натуральность тембра
- Организация Full TTS анализа в Windows без тяжелых зависимостей (например, NeMo)

---

## 9. Воспроизводимость

Подробные команды запуска обучения, инференса и Full TTS анализа вынесены в основной `README.md` репозитория.

В репозитории также приложен Colab-ноутбук:
- `demo/demo_colab.ipynb`

Он демонстрирует:
- установку зависимостей
- скачивание чекпоинта
- подготовку MOS-данных
- запуск `synthesize.py`
- прослушивание результатов

---

## Приложение: иллюстрации анализа

### Сравнение waveform на MOS-примере
![Waveform MOS example](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/mos1_waveforms.png)

### Сравнение waveform на примере из RUSLAN
![Waveform RUSLAN example](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/ruslan_example_waveforms.png)

### Сравнение log-mel на MOS-примере
![Mel MOS example](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/mos1_mels.png)

### Full TTS (MMS vs мой вокодер): RUSLAN, waveform
![Full TTS RUSLAN waveform](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/ruslan_fulltts_mms_00_waveforms.png)

### Full TTS (MMS vs мой вокодер): RUSLAN, log-mel
![Full TTS RUSLAN mel](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/ruslan_fulltts_mms_00_mels.png)

### Full TTS (MMS vs мой вокодер): MOS, waveform
![Full TTS MOS waveform](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/mos_fulltts_mms_03_waveforms.png)

### Full TTS (MMS vs мой вокодер): MOS, log-mel
![Full TTS MOS mel](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/mos_fulltts_mms_03_mels.png)

### Full TTS (MMS vs мой вокодер): custom, waveform
![Full TTS custom waveform](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/custom_fulltts_mms_06_waveforms.png)

### Full TTS (MMS vs мой вокодер): custom, log-mel
![Full TTS custom mel](https://github.com/1vlex/hw3-tts-vocoder/blob/main/report/figures/full_tts_mms/custom_fulltts_mms_06_mels.png)
